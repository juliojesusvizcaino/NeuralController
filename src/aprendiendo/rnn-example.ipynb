{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global config variables\n",
    "num_steps = 5 # number of truncated backprop steps ('n' in the discussion above)\n",
    "batch_size = 200\n",
    "num_classes = 2\n",
    "state_size = 4\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(size=1000000):\n",
    "    X = np.array(np.random.choice(2, size=(size,)))\n",
    "    Y = []\n",
    "    for i in range(size):\n",
    "        threshold = 0.5\n",
    "        if X[i-3] == 1:\n",
    "            threshold += 0.5\n",
    "        if X[i-8] == 1:\n",
    "            threshold -= 0.25\n",
    "        if np.random.rand() > threshold:\n",
    "            Y.append(0)\n",
    "        else:\n",
    "            Y.append(1)\n",
    "    return X, np.array(Y)\n",
    "\n",
    "# adapted from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/reader.py\n",
    "def gen_batch(raw_data, batch_size, num_steps):\n",
    "    raw_x, raw_y = raw_data\n",
    "    data_length = len(raw_x)\n",
    "\n",
    "    # partition raw data into batches and stack them vertically in a data matrix\n",
    "    batch_partition_length = data_length // batch_size\n",
    "    data_x = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    data_y = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    for i in range(batch_size):\n",
    "        data_x[i] = raw_x[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "        data_y[i] = raw_y[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "    # further divide batch partitions into num_steps for truncated backprop\n",
    "    epoch_size = batch_partition_length // num_steps\n",
    "\n",
    "    for i in range(epoch_size):\n",
    "        x = data_x[:, i * num_steps:(i + 1) * num_steps]\n",
    "        y = data_y[:, i * num_steps:(i + 1) * num_steps]\n",
    "        yield (x, y)\n",
    "\n",
    "def gen_epochs(n, num_steps):\n",
    "    for i in range(n):\n",
    "        yield gen_batch(gen_data(), batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Placeholders\n",
    "\"\"\"\n",
    "\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_steps], name='input_placeholder')\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_steps], name='labels_placeholder')\n",
    "init_state = tf.zeros([batch_size, state_size])\n",
    "\n",
    "\"\"\"\n",
    "RNN Inputs\n",
    "\"\"\"\n",
    "\n",
    "# Turn our x placeholder into a list of one-hot tensors:\n",
    "# rnn_inputs is a list of num_steps tensors with shape [batch_size, num_classes]\n",
    "x_one_hot = tf.one_hot(x, num_classes)\n",
    "rnn_inputs = tf.unpack(x_one_hot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Definition of rnn_cell\n",
    "\n",
    "This is very similar to the __call__ method on Tensorflow's BasicRNNCell. See:\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell.py\n",
    "\"\"\"\n",
    "with tf.variable_scope('rnn_cell'):\n",
    "    W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "    b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "def rnn_cell(rnn_input, state):\n",
    "    with tf.variable_scope('rnn_cell', reuse=True):\n",
    "        W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "        b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "    return tf.tanh(tf.matmul(tf.concat(1, [rnn_input, state]), W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adding rnn_cells to graph\n",
    "\n",
    "This is a simplified version of the \"rnn\" function from Tensorflow's api. See:\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn.py\n",
    "\"\"\"\n",
    "state = init_state\n",
    "rnn_outputs = []\n",
    "for rnn_input in rnn_inputs:\n",
    "    state = rnn_cell(rnn_input, state)\n",
    "    rnn_outputs.append(state)\n",
    "final_state = rnn_outputs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Predictions, loss, training step\n",
    "\n",
    "Losses and total_loss are simlar to the \"sequence_loss_by_example\" and \"sequence_loss\"\n",
    "functions, respectively, from Tensorflow's api. See:\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/seq2seq.py\n",
    "\"\"\"\n",
    "\n",
    "#logits and predictions\n",
    "with tf.variable_scope('softmax'):\n",
    "    W = tf.get_variable('W', [state_size, num_classes])\n",
    "    b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "logits = [tf.matmul(rnn_output, W) + b for rnn_output in rnn_outputs]\n",
    "predictions = [tf.nn.softmax(logit) for logit in logits]\n",
    "\n",
    "# Turn our y placeholder into a list labels\n",
    "y_as_list = [tf.squeeze(i, squeeze_dims=[1]) for i in tf.split(1, num_steps, y)]\n",
    "\n",
    "#losses and train_step\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(logit,label) for \\\n",
    "          logit, label in zip(logits, y_as_list)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_step = tf.train.AdagradOptimizer(learning_rate).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to train the network\n",
    "\"\"\"\n",
    "\n",
    "def train_network(num_epochs, num_steps, state_size=4, verbose=True):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        training_losses = []\n",
    "        for idx, epoch in enumerate(gen_epochs(num_epochs, num_steps)):\n",
    "            training_loss = 0\n",
    "            training_state = np.zeros((batch_size, state_size))\n",
    "            if verbose:\n",
    "                print(\"\\nEPOCH\", idx)\n",
    "            for step, (X, Y) in enumerate(epoch):\n",
    "                tr_losses, training_loss_, training_state, _ = \\\n",
    "                    sess.run([losses,\n",
    "                              total_loss,\n",
    "                              final_state,\n",
    "                              train_step],\n",
    "                                  feed_dict={x:X, y:Y, init_state:training_state})\n",
    "                training_loss += training_loss_\n",
    "                if step % 100 == 0 and step > 0:\n",
    "                    if verbose:\n",
    "                        print(\"Average loss at step\", step,\n",
    "                              \"for last 250 steps:\", training_loss/100)\n",
    "                    training_losses.append(training_loss/100)\n",
    "                    training_loss = 0\n",
    "\n",
    "    return training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\nEPOCH', 0)\n('Average loss at step', 100, 'for last 250 steps:', 0.64489110708236697)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Average loss at step', 200, 'for last 250 steps:', 0.60651493906974796)\n('Average loss at step', 300, 'for last 250 steps:', 0.55658382773399351)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Average loss at step', 400, 'for last 250 steps:', 0.51887654215097423)\n('Average loss at step', 500, 'for last 250 steps:', 0.51922590762376786)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Average loss at step', 600, 'for last 250 steps:', 0.52023106098175054)\n('Average loss at step', 700, 'for last 250 steps:', 0.51834169149398801)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Average loss at step', 800, 'for last 250 steps:', 0.52054981797933575)\n('Average loss at step', 900, 'for last 250 steps:', 0.52024491041898724)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6a0f785450>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAFdCAYAAACNYC65AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nV/wbSPoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6a384ca290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_losses = train_network(1,num_steps)\n",
    "plt.plot(training_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named basic_rnn",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f82b899fb858>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mbasic_rnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_learning_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named basic_rnn"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import basic_rnn\n",
    "def plot_learning_curve(num_steps, state_size=4, epochs=1):\n",
    "    global losses, total_loss, final_state, train_step, x, y, init_state\n",
    "    tf.reset_default_graph()\n",
    "    g = tf.get_default_graph()\n",
    "    losses, total_loss, final_state, train_step, x, y, init_state = \\\n",
    "        basic_rnn.setup_graph(g,\n",
    "            basic_rnn.RNN_config(num_steps=num_steps, state_size=state_size))\n",
    "    res = train_network(epochs, num_steps, state_size=state_size, verbose=False)\n",
    "    plt.plot(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}